{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/duyeoungryu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/duyeoungryu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "sentences = []\n",
    "for s in movie_reviews.sents():\n",
    "    s.insert(0, \"SS\")\n",
    "    s.append(\"SE\")\n",
    "    if len(s) > 4:\n",
    "        sentences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SS', 'they', 'get', 'into', 'an', 'accident', '.', 'SE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_bigram(sentences):\n",
    "    bigram = {} # 저장\n",
    "    for s in sentences:\n",
    "        context = \"SS\"\n",
    "        for i, w in enumerate(s[1:]):\n",
    "            if context not in bigram:\n",
    "                bigram[context] = Counter()\n",
    "            if bigram[context][w] == 0: # 해당 컨텍스트에 단어가 없으면 \n",
    "                bigram[context][w] = 1 # 1추가\n",
    "            bigram[context][w] += 1 # 나온 횟수 추가\n",
    "            context = w\n",
    "            \n",
    "    # 확률 형태로 바꾸는 작업\n",
    "    for context in bigram.keys():\n",
    "        total = sum(bigram[context].values())\n",
    "        for w in bigram[context]:\n",
    "            bigram[context][w] /= total\n",
    "    return bigram\n",
    "bigram = calculate_bigram(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.11231263830320237),\n",
       " ('it', 0.043575076893101194),\n",
       " ('i', 0.03379121261464379),\n",
       " ('but', 0.02523207103391647),\n",
       " ('and', 0.024160438673402642),\n",
       " ('he', 0.023269731256871668),\n",
       " ('in', 0.023102723616272112),\n",
       " ('this', 0.022963550582439148),\n",
       " ('there', 0.0180507424881355),\n",
       " ('as', 0.013249272820898222)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram['SS'].most_common(10) # 첫단어로 많이 나오는 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017556848228450557"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram['i']['am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SE': 0.9612387969875893,\n",
       "         \"'\": 0.0010735373054213634,\n",
       "         '\"': 0.02922949299760894,\n",
       "         ')': 0.00821418695814831,\n",
       "         \"''\": 6.506286699523415e-05,\n",
       "         ']': 0.0001789228842368939})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram['.'],\n",
    "# 문장이 끝날 확률\n",
    "# 인용문\n",
    "# 괄호안에 있는 설명문\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_score(s):\n",
    "    p = 0.0\n",
    "    for i in range(len(s) - 1):\n",
    "        c = s[i]\n",
    "        w = s[i + 1]\n",
    "        p += np.log(bigram[c][w] + np.finfo(float).eps) \n",
    "        # 너무 작은 값을 계속곱하면 결과가 보기 힘듬 그러므로 log를 취한다음 더하기로 연산\n",
    "        # eps 는 표현가능한 가장 작은값\n",
    "    return np.exp(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.288036438066686e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 코퍼스 안에서는 굉장히 큰 확률\n",
    "# 사용예는 문법이 맞나 안맞나를 판단하는데 사용될수 있다.\n",
    "test_sentence = [\"i\", \"am\", \"a\", \"boy\", \".\"]\n",
    "sentence_score(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    c = \"SS\"\n",
    "    sentence = []\n",
    "    while True:\n",
    "        if c not in bigram:\n",
    "            break\n",
    "        words, probs = zip(*[(k, v) for k, v in bigram[c].items()])\n",
    "        idx = np.argmax(np.random.multinomial(1, probs, (1,)))\n",
    "        w = words[idx]\n",
    "        \n",
    "        if w == \"SE\":\n",
    "            break\n",
    "        elif w in [\"i\", \"ii\", \"iii\"]:\n",
    "            w2 = w.upper()\n",
    "        elif w in [\"mr\", \"luc\", \"i\", \"robin\", \"williams\", \"cindy\", \"crawford\"]:\n",
    "            w2 = w.title()\n",
    "        else:\n",
    "            w2 = w\n",
    "        \n",
    "        if c == \"SS\":\n",
    "            sentence.append(w2.title())\n",
    "        elif c in [\"`\", \"\\\"\", \"'\", \"(\"]:\n",
    "            sentence.append(w2)\n",
    "        elif w in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
    "            sentence.append(w2)\n",
    "        else:\n",
    "            sentence.append(\" \" + w2)\n",
    "            \n",
    "        c = w\n",
    "    return \"\".join(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se가 나올때까지 계속 카테고리분포 모형을 만들어 단어 확률로 다음단어를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexandre dumas may suspect he at being can be honest here goes awol, but he trusts affleck - see this documentary.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(82)\n",
    "# 문법이 안맞는 경우는 bigramd이기에 문법에대한 확인은 어렵다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
    "    data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "    data = data[1:]   # header 제외\n",
    "    \n",
    "docs = [row[1] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "tagger = Twitter()\n",
    "\n",
    "def tokenize(doc):\n",
    "    return [\"SS\"] + ['/'.join(t) for t in tagger.pos(doc, norm=True, stem=True)] + [\"SE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 10s, sys: 1.65 s, total: 3min 12s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = [tokenize(d) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글은 변환작업이 필요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
